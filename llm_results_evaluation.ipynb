{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\"India\", \"China\", \"U.S.\", \"Indonesia\", \"Nigeria\", \"Brazil\", \"Russia\", \"Mexico\", \"Japan\",\n",
    "             \"Ethiopia\", \"Egypt\", \"Iran\", \"France\", \"Thailand\", \"Argentina\", \"Morocco\", \"Saudi_Arabia\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1-Adhere Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = \"gpt-4o-mini\"\n",
    "llm_model = \"gpt-4o\"\n",
    "# llm_model = \"gpt-4-turbo\",\n",
    "# llm_model = \"gpt-4\"\n",
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# llm_model = \"gpt-3.5\"\n",
    "\n",
    "prompt_methods = [\n",
    "    # non-agent\n",
    "    \"non_agent\", \"non_agent_cs\",\n",
    "    # agent\n",
    "    \"original\", \n",
    "    \"examples_updated_2n1s\", \"examples_updated_2s\", \n",
    "    \"system_prompt_updated\",\n",
    "    \"system_prompt_updated_stop_2n\", \"system_prompt_updated_stop_2s\",\n",
    "]\n",
    "\n",
    "subsets = [\"online_shopping\", \"social_discussion_forum\"]\n",
    "\n",
    "# Iterate through prompt methods\n",
    "for prompt_method in prompt_methods:\n",
    "    print(f\"\\n{prompt_method}\")\n",
    "\n",
    "    # Iterate through subsets\n",
    "    for subset in subsets:\n",
    "        count = 0\n",
    "        total_count = 0\n",
    "\n",
    "        # Define the folder path\n",
    "        folder_path = f\"./llm_evaluation_results/s1_adhere/{subset}/{prompt_method}/{llm_model}\"\n",
    "\n",
    "        # Iterate through selected countries\n",
    "        for country in countries:\n",
    "            llm_evaluation_results_file_path = f\"{folder_path}/{country}.json\"\n",
    "\n",
    "            # Load the JSON file\n",
    "            with open(llm_evaluation_results_file_path, \"r\") as file:\n",
    "                llm_evaluation_results = json.load(file)\n",
    "\n",
    "            # Process results\n",
    "            for result in llm_evaluation_results:\n",
    "                if \"Yes\" in result[\"llm_evaluation_result\"] or \"YES\" in result[\"llm_evaluation_result\"]:\n",
    "                    count += 1\n",
    "                total_count += 1\n",
    "\n",
    "        # Print results\n",
    "        percentage = round(count / total_count * 100, 2) if total_count > 0 else 0\n",
    "        print(f\"{subset}: {percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1-Violate Awareness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = \"gpt-4o-mini\"\n",
    "llm_model = \"gpt-4o\"\n",
    "# llm_model = \"gpt-4-turbo\",\n",
    "# llm_model = \"gpt-4\"\n",
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# llm_model = \"gpt-3.5\"\n",
    "\n",
    "prompt_methods = [\n",
    "    # non-agent\n",
    "    \"non_agent\", \"non_agent_cs\",\n",
    "    # agent\n",
    "    \"original\", \n",
    "    \"examples_updated_2n1s\", \"examples_updated_2s\", \n",
    "    \"system_prompt_updated\",\n",
    "    \"system_prompt_updated_stop_2n\", \"system_prompt_updated_stop_2s\",\n",
    "]\n",
    "\n",
    "subsets = [\"online_shopping\", \"social_discussion_forum\"]\n",
    "\n",
    "# Iterate through prompt methods\n",
    "for prompt_method in prompt_methods:\n",
    "    print(f\"\\n{prompt_method}\")\n",
    "\n",
    "    # Iterate through subsets\n",
    "    for subset in subsets:\n",
    "        count = 0\n",
    "        total_count = 0\n",
    "\n",
    "        # Define the folder path\n",
    "        folder_path = f\"./llm_evaluation_results/s1_violate_r1/{subset}/{prompt_method}/{llm_model}\"\n",
    "\n",
    "        # Iterate through selected countries\n",
    "        for country in countries:\n",
    "            llm_evaluation_results_file_path = f\"{folder_path}/{country}.json\"\n",
    "\n",
    "            # Load the JSON file\n",
    "            with open(llm_evaluation_results_file_path, \"r\") as file:\n",
    "                llm_evaluation_results = json.load(file)\n",
    "\n",
    "            # Process results\n",
    "            for result in llm_evaluation_results:\n",
    "                if \"Yes\" in result[\"llm_evaluation_result\"] or \"YES\" in result[\"llm_evaluation_result\"]:\n",
    "                    count += 1\n",
    "                total_count += 1\n",
    "\n",
    "        # Print results\n",
    "        percentage = round(count / total_count * 100, 2) if total_count > 0 else 0\n",
    "        print(f\"{subset}: {percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1-Violate Educational Info Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = \"gpt-4o-mini\"\n",
    "llm_model = \"gpt-4o\"\n",
    "# llm_model = \"gpt-4-turbo\",\n",
    "# llm_model = \"gpt-4\"\n",
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# llm_model = \"gpt-3.5\"\n",
    "\n",
    "prompt_methods = [\n",
    "    # non-agent\n",
    "    \"non_agent\", \"non_agent_cs\",\n",
    "    # agent\n",
    "    \"original\", \n",
    "    \"examples_updated_2n1s\", \"examples_updated_2s\", \n",
    "    \"system_prompt_updated\",\n",
    "    \"system_prompt_updated_stop_2n\", \"system_prompt_updated_stop_2s\",\n",
    "]\n",
    "\n",
    "subsets = [\"online_shopping\", \"social_discussion_forum\"]\n",
    "\n",
    "# Iterate through prompt methods\n",
    "for prompt_method in prompt_methods:\n",
    "    print(f\"\\n{prompt_method}\")\n",
    "    \n",
    "    # Iterate through subsets\n",
    "    for subset in subsets:\n",
    "        count = 0\n",
    "        total_count = 0\n",
    "\n",
    "        # Define the folder path\n",
    "        folder_path = f\"./llm_evaluation_results/s1_violate_r2/{subset}/{prompt_method}/{llm_model}\"\n",
    "\n",
    "        # Iterate through selected countries\n",
    "        for country in countries:\n",
    "            llm_evaluation_results_file_path = f\"{folder_path}/{country}.json\"\n",
    "        \n",
    "            llm_evaluation_results = json.load(open(llm_evaluation_results_file_path, \"r\"))\n",
    "            \n",
    "            for result in llm_evaluation_results:\n",
    "                if \"(B)\" in result[f\"llm_evaluation_result_r2\"] or \"[B]\" in result[f\"llm_evaluation_result_r2\"] or \"B ##\" in result[f\"llm_evaluation_result_r2\"]:\n",
    "                    count += 1\n",
    "                total_count += 1\n",
    "        \n",
    "        # Print results\n",
    "        percentage = round(count / total_count * 100, 2) if total_count > 0 else 0\n",
    "        print(f\"{subset}: {percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 Violation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = \"gpt-4o-mini\"\n",
    "llm_model = \"gpt-4o\"\n",
    "# llm_model = \"gpt-4-turbo\",\n",
    "# llm_model = \"gpt-4\"\n",
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# llm_model = \"gpt-3.5\"\n",
    "\n",
    "prompt_methods = [\n",
    "    # agent\n",
    "    \"original\", \n",
    "    \"examples_updated_2n1s\", \"examples_updated_2s\", \n",
    "    \"system_prompt_updated_stop_2n\", \"system_prompt_updated_stop_2s\",\n",
    "]\n",
    "\n",
    "subsets = [\"social_discussion_forum\"]\n",
    "\n",
    "# Iterate through prompt methods\n",
    "for prompt_method in prompt_methods:\n",
    "    print(f\"\\n{prompt_method}\")\n",
    "    \n",
    "    # Iterate through subsets\n",
    "    for subset in subsets:\n",
    "        count = 0\n",
    "        total_count = 0\n",
    "\n",
    "        # Define the folder path\n",
    "        folder_path = f\"./llm_evaluation_results/s2/{prompt_method}/social_discussion_forum/{llm_model}\"\n",
    "        \n",
    "        # Iterate through selected countries\n",
    "        for country in countries:\n",
    "            llm_evaluation_results_file_path = f\"{folder_path}/{country}.json\"\n",
    "        \n",
    "            llm_evaluation_results = json.load(open(llm_evaluation_results_file_path, \"r\"))\n",
    "            \n",
    "            for result in llm_evaluation_results:\n",
    "                if \"(A)\" in result[f\"llm_evaluation_result\"] or \"[A]\" in result[f\"llm_evaluation_result\"] or \"A ##\" in result[f\"llm_evaluation_result\"]:\n",
    "                    count += 1\n",
    "                total_count += 1\n",
    "        \n",
    "        # Print results\n",
    "        percentage = round(count / total_count * 100, 2) if total_count > 0 else 0\n",
    "        print(f\"{subset}: {percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = \"gpt-4o-mini\"\n",
    "llm_model = \"gpt-4o\"\n",
    "# llm_model = \"gpt-4-turbo\",\n",
    "# llm_model = \"gpt-4\"\n",
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# llm_model = \"gpt-3.5\"\n",
    "\n",
    "prompt_methods = [\n",
    "    # agent\n",
    "    \"original\", \n",
    "    \"examples_updated_2n1s\", \"examples_updated_2s\", \n",
    "    \"system_prompt_updated_stop_2n\", \"system_prompt_updated_stop_2s\",\n",
    "]\n",
    "\n",
    "# Iterate through prompt methods\n",
    "for prompt_method in prompt_methods:\n",
    "    print(f\"\\n{prompt_method}\")\n",
    "    \n",
    "    # Iterate through subsets\n",
    "    for subset in subsets:\n",
    "        \n",
    "        violation_count_1 = 0\n",
    "        total_count_1 = 0\n",
    "\n",
    "        # Define the round 1 folder path\n",
    "        folder_path_1 = f\"./llm_evaluation_results/s2/{prompt_method}/online_shopping_r1/{llm_model}\"\n",
    "\n",
    "        # Iterate through selected countries\n",
    "        for country in countries:\n",
    "            \n",
    "            llm_evaluation_results_file_path = f\"{folder_path_1}/{country}.json\"\n",
    "            llm_evaluation_results = json.load(open(llm_evaluation_results_file_path, \"r\"))\n",
    "            \n",
    "            for result in llm_evaluation_results:\n",
    "                total_count_1 += 1\n",
    "                if \"(A)\" in result[f\"llm_evaluation_result\"] or \"[A]\" in result[f\"llm_evaluation_result\"] or \"A ##\" in result[f\"llm_evaluation_result\"]:\n",
    "                    violation_count_1 += 1\n",
    "\n",
    "        \n",
    "        # Define the round 2 folder path\n",
    "        folder_path_2 = f\"./llm_evaluation_results/s2/{prompt_method}/online_shopping_r2/{llm_model}\"\n",
    "\n",
    "        violation_count_2 = 0\n",
    "        \n",
    "        # Iterate through selected countries\n",
    "        for country in countries:\n",
    "            \n",
    "            llm_evaluation_results_file_path = f\"{folder_path_2}/{country}.json\"\n",
    "            llm_evaluation_results = json.load(open(llm_evaluation_results_file_path, \"r\"))\n",
    "            \n",
    "            for result in llm_evaluation_results:\n",
    "                if \"(A)\" in result[f\"llm_evaluation_result_r2\"] or \"[A]\" in result[f\"llm_evaluation_result_r2\"] or \"A ##\" in result[f\"llm_evaluation_result\"]:\n",
    "                    violation_count_2 += 1\n",
    "        \n",
    "        print(f\"Total violation:\", round(violation_count_1 / total_count_1 * 100 + violation_count_2 / total_count_1 * 100, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenteval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
